{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Retrieval\n",
    "\n",
    "\n",
    "When building retrieval-augmented generation (RAG) applications, various retrieval parameters and strategies must be considered, such as chunk size, vector search, keyword search, and hybrid search.\n",
    "\n",
    "**Concept**: What if we could simultaneously try multiple strategies and use an AI/reranker/LLM to prune the results?\n",
    "\n",
    "This approach serves two main purposes:\n",
    "\n",
    "1. **Enhanced Retrieval**: By pooling results from multiple strategies, we can achieve better (though more costly) retrieved results, assuming the reranker is effective.\n",
    "\n",
    "2. **Benchmarking**: It provides a way to benchmark different retrieval strategies against each other with respect to the reranker.\n",
    "\n",
    "## Key Purposes of the Ensemble Retriever\n",
    "\n",
    "1. **Multi-Strategy Retrieval**: Try multiple retrieval strategies simultaneously, such as different chunk sizes and index types (vector, keyword, hybrid search). This allows for comparing the effectiveness of various approaches in one shot.\n",
    "\n",
    "2. **Pooling Results**: Pool results from different retrieval strategies, leading to better overall retrieved results, assuming an effective reranker is used to prune the ensemble results.\n",
    "\n",
    "3. **Benchmarking Performance**: Benchmark and compare the performance of different retrieval strategies against each other with respect to the reranker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 llama-index-embeddings-openai==0.1.9 qdrant-client==1.9.1 llama-index-vector-stores-qdrant==0.2.8 llama-index-llms-openai==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv(\"\")\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "from utils import setup_llm, setup_embed_model, setup_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDRANT_URL = os.environ['QDRANT_URL'] or getpass(\"Enter your Qdrant URL:\")\n",
    "\n",
    "QDRANT_URL=\":memory:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_API_KEY = os.environ['QDRANT_API_KEY'] or  getpass(\"Enter your Qdrant API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from utils import setup_llm, setup_embed_model\n",
    "\n",
    "setup_llm(\n",
    "    provider=\"openai\",\n",
    "    api_key=OPENAI_API_KEY, \n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0.75, \n",
    "    system_prompt=\"\"\"Use ONLY the provided context and generate a complete, coherent answer to the user's query. \n",
    "    Your response must be grounded in the provided context and relevant to the essence of the user's query.\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "setup_embed_model(\n",
    "    provider=\"openai\", \n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=OPENAI_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from utils import get_documents_from_docstore, group_documents_by_author, sample_documents\n",
    "\n",
    "documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "documents_by_author = group_documents_by_author(documents)\n",
    "\n",
    "senpai_documents = sample_documents(documents_by_author, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 128\n",
      "Chunk Size: 256\n",
      "Chunk Size: 512\n",
      "Chunk Size: 1024\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "chunk_sizes = [128, 256, 512, 1024]\n",
    "\n",
    "nodes_list = []\n",
    "\n",
    "vector_indices = []\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    print(f\"Chunk Size: {chunk_size}\")\n",
    "    splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=8)\n",
    "    nodes = splitter.get_nodes_from_documents(senpai_documents)\n",
    "\n",
    "    # add chunk size to nodes to track later\n",
    "    for node in nodes:\n",
    "        node.metadata[\"chunk_size\"] = chunk_size\n",
    "        node.excluded_embed_metadata_keys = [\"chunk_size\"]\n",
    "        node.excluded_llm_metadata_keys = [\"chunk_size\"]\n",
    "\n",
    "    nodes_list.append(nodes)\n",
    "\n",
    "    # build vector index\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    vector_indices.append(vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Create an Ensemble Retriever\n",
    "\n",
    "1. **Define Index Nodes**: Create separate index nodes for each retrieval strategy you want to try (e.g., retrievers for different chunk sizes).\n",
    "\n",
    "2. **Create a Summary Index**: Combine all the index nodes into a single summary index.\n",
    "\n",
    "3. **Set Up a Recursive Retriever**: Define a recursive retriever with the root node being the summary index retriever. This will fetch results from all the underlying retrievers when a query is run.\n",
    "\n",
    "4. **Define a Reranker**: Use a reranker (e.g., LLM-based, Cohere, Sentence Transformer) to process and prune the final retrieved set of nodes.\n",
    "\n",
    "5. **Integrate with a Query Engine**: Create a retriever query engine that combines the recursive retriever and the reranker.\n",
    "\n",
    "6. **Run Queries**: Execute queries through the retriever query engine to get results that leverage the ensemble of retrievers, postprocessed by the reranker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below...\n",
    "\n",
    "â€¢  **Define Index Nodes**: Create a separate `IndexNode` for the vector retriever corresponding to each chunk size (e.g., a retriever for chunk size 128, another for chunk size 256, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "retriever_dict = {}\n",
    "\n",
    "retriever_nodes = []\n",
    "\n",
    "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n",
    "    node_id = f\"chunk_{chunk_size}\"\n",
    "    node = IndexNode(\n",
    "        text=(\n",
    "            \"Retrieves relevant context from the Llama 2 paper (chunk size\"\n",
    "            f\" {chunk_size})\"\n",
    "        ),\n",
    "        index_id=node_id,\n",
    "    )\n",
    "    retriever_nodes.append(node)\n",
    "    retriever_dict[node_id] = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate Index Nodes**: Combine all `IndexNodes` into a single `SummaryIndex`. \n",
    "\n",
    "[`SummaryIndex`](https://github.com/run-llama/llama_index/blob/7849b1a851d88ee28e1bfd05d19f18e40d5b8e10/llama-index-core/llama_index/core/indices/list/base.py#L33)  is a simple list-based data structure. During index construction, `SummaryIndex` takes in a dataset of text documents as input, chunks them up into smaller document chunks, and concatenates them into a list.\n",
    "\n",
    "\n",
    "*Index Construction*\n",
    "\n",
    "1. **Chunking**: The document texts are divided into chunks.\n",
    "2. **Node Creation**: Each chunk is converted into a node.\n",
    "3. **Storage**: These nodes are stored in a list.\n",
    "\n",
    "*Query Time*\n",
    "\n",
    "An initial answer to the query is constructed using the first text chunk. The answer is then refined through feeding in subsequent text chunks as context. Refinement could mean keeping the original answer, making small edits to the original answer, or rewriting the original answer completely.\n",
    "\n",
    "1. **Iteration**: The summary index iterates through the nodes.\n",
    "2. **Optional Filtering**: Some filter parameters can be applied.\n",
    "3. **Answer Synthesis**: An answer is synthesized from all the nodes.\n",
    "\n",
    "When this retriever is called, **all** nodes are returned.\n",
    "\n",
    "**Recursive Retriever Setup**: Define a Recursive Retriever with the root node being the summary index retriever. This retriever will first fetch all nodes from the summary index and then recursively call the vector retriever for each chunk size.\n",
    "\n",
    "1. **Recursive Exploration**: The retriever will follow links from nodes to other retrievers or query engines.\n",
    "\n",
    "2. **IndexNode Handling**: For any retrieved nodes that are `IndexNodes`, it will:\n",
    "    - Explore the linked retriever or query engine.\n",
    "    - Query the linked retriever or query engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core import SummaryIndex\n",
    "\n",
    "summary_index = SummaryIndex(retriever_nodes)\n",
    "\n",
    "retriever = RecursiveRetriever(\n",
    "    root_id=\"root\",\n",
    "    retriever_dict={\"root\": summary_index.as_retriever(), **retriever_dict},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = await retriever.aretrieve(\n",
    "    \"How can I effectively identify and leverage new opportunities in the tech industry?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8\n",
      "128\n",
      "Think about what product or service society wants but does not yet know how to get. You want to become the person who delivers it and delivers it at scale. That is really the challenge of how to make money. Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology.\n",
      "128\n",
      "You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move\n",
      "256\n",
      "It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move\n",
      "256\n",
      "Youre more likely to have skills society does not yet know how to train other people to do. If someone can train other people how to do something, then they can replace you. If they can replace you, then they dont have to pay you a lot. You want to know how to do something other people dont know how to do at the time period when those skills are in demand. If they can train you to do it, then eventually they will train a computer to do it. You get rewarded by society for giving it what it wants and doesnt know how to get elsewhere. A lot of people think you can go to school and study for how to make money, but the reality is, theres no skill called business. Think about what product or service society wants but does not yet know how to get. You want to become the person who delivers it and delivers it at scale. That is really the challenge of how to make money. Now, the problem is becoming good at whatever it is.\n",
      "512\n",
      "Youre more likely to have skills society does not yet know how to train other people to do. If someone can train other people how to do something, then they can replace you. If they can replace you, then they dont have to pay you a lot. You want to know how to do something other people dont know how to do at the time period when those skills are in demand. If they can train you to do it, then eventually they will train a computer to do it. You get rewarded by society for giving it what it wants and doesnt know how to get elsewhere. A lot of people think you can go to school and study for how to make money, but the reality is, theres no skill called business. Think about what product or service society wants but does not yet know how to get. You want to become the person who delivers it and delivers it at scale. That is really the challenge of how to make money. Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move\n",
      "512\n",
      "Obviously, not a single person may know this. You may pull a team together to do it where each have different skill sets, but that combined entity would have specific knowledge in technology and in real estate. It would have massive accountability because that companys name would be a very high-risk, high-reward effort attached to the whole thing, and people would devote their lives to it and take on significant risk. It would have leverage in code with lots of developers. It would have capital with investors putting money in and the founders own capital. It would have some of the highest-quality labor you can find, which is high-quality engineers, designers, and marketers who are working on the company. Then, you may end up with a Trulia, Redfin, or Zillow company, and then the upside could potentially be in the billions of dollars, or the hundreds of millions of dollars. Each level has increasing leverage, increasing accountability, increasingly specific knowledge. Youre adding in moneybased leverage on top of labor-based leverage. Adding in code-based leverage on top of money and labor allows you to actually create something bigger and bigger and get closer and closer to owning all the upside, not just being paid a salary. You start as a salaried employee. But you want to work your way up to try and get higher leverage, more accountability, and specific knowledge. The combination of those over a long period of time with the magic of compound interest will make you wealthy. The one thing you have to avoid is the risk of ruin. Avoiding ruin means stay out of jail. So, dont do anything ille-\n",
      "1024\n",
      "Youre more likely to have skills society does not yet know how to train other people to do. If someone can train other people how to do something, then they can replace you. If they can replace you, then they dont have to pay you a lot. You want to know how to do something other people dont know how to do at the time period when those skills are in demand. If they can train you to do it, then eventually they will train a computer to do it. You get rewarded by society for giving it what it wants and doesnt know how to get elsewhere. A lot of people think you can go to school and study for how to make money, but the reality is, theres no skill called business. Think about what product or service society wants but does not yet know how to get. You want to become the person who delivers it and delivers it at scale. That is really the challenge of how to make money. Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move\n",
      "1024\n",
      "Obviously, not a single person may know this. You may pull a team together to do it where each have different skill sets, but that combined entity would have specific knowledge in technology and in real estate. It would have massive accountability because that companys name would be a very high-risk, high-reward effort attached to the whole thing, and people would devote their lives to it and take on significant risk. It would have leverage in code with lots of developers. It would have capital with investors putting money in and the founders own capital. It would have some of the highest-quality labor you can find, which is high-quality engineers, designers, and marketers who are working on the company. Then, you may end up with a Trulia, Redfin, or Zillow company, and then the upside could potentially be in the billions of dollars, or the hundreds of millions of dollars. Each level has increasing leverage, increasing accountability, increasingly specific knowledge. Youre adding in moneybased leverage on top of labor-based leverage. Adding in code-based leverage on top of money and labor allows you to actually create something bigger and bigger and get closer and closer to owning all the upside, not just being paid a salary. You start as a salaried employee. But you want to work your way up to try and get higher leverage, more accountability, and specific knowledge. The combination of those over a long period of time with the magic of compound interest will make you wealthy. The one thing you have to avoid is the risk of ruin. Avoiding ruin means stay out of jail. So, dont do anything ille-\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nodes: {len(nodes)}\")\n",
    "for node in nodes:\n",
    "    print(node.node.metadata[\"chunk_size\"])\n",
    "    print(node.node.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rerank Final Results**: Rerank the results obtained from all vector retrievers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "reranker = CohereRerank(top_n=5, api_key=CO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define retriever query engine to integrate the recursive retriever + reranker together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"How can I effectively identify and leverage new opportunities in the tech industry?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** To effectively identify and leverage new opportunities in the tech industry, focus on acquiring unique skills that are in demand but not easily replicable. Stay vigilant for emerging trends and technologies that require these specialized skills. In the meantime, build your personal brand through platforms like Twitter and YouTube, and offer free work to gain visibility and reputation. By doing so, you position yourself as an expert who can provide solutions that are not readily available elsewhere. When the right opportunity arises, you will be ready to take advantage of it and deliver at scale."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/5`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 39d200ea-1bdf-4b97-a9f3-d48dfc26ac69<br>**Similarity:** 0.37433314<br>**Text:** You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move<br>**Metadata:** {'page_number': 27, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant', 'chunk_size': 128}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/5`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b3570882-0fa8-4483-b34d-f1b24323ccf4<br>**Similarity:** 0.15546273<br>**Text:** It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move<br>**Metadata:** {'page_number': 27, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant', 'chunk_size': 256}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/5`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e44026ab-e457-4527-b4d8-c6656472393c<br>**Similarity:** 0.09351231<br>**Text:** Youre more likely to have skills society does not yet know how to train other people to do. If someone can train other people how to do something, then they can replace you. If they can replace you, then they dont have to pay you a lot. You want to know how to do something other people dont know how to do at the time period when those skills are in demand. If they can train you to do it, then eventually they will train a computer to do it. You get rewarded by society for giving it what it wan...<br>**Metadata:** {'page_number': 27, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant', 'chunk_size': 256}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 4/5`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b323849e-faa2-4021-80e1-0ae2e397fd69<br>**Similarity:** 0.07382971<br>**Text:** Think about what product or service society wants but does not yet know how to get. You want to become the person who delivers it and delivers it at scale. That is really the challenge of how to make money. Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology.<br>**Metadata:** {'page_number': 27, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant', 'chunk_size': 128}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 5/5`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e35d4bea-471b-4768-a011-668d6a2694e3<br>**Similarity:** 0.06804042<br>**Text:** Youre more likely to have skills society does not yet know how to train other people to do. If someone can train other people how to do something, then they can replace you. If they can replace you, then they dont have to pay you a lot. You want to know how to do something other people dont know how to do at the time period when those skills are in demand. If they can train you to do it, then eventually they will train a computer to do it. You get rewarded by society for giving it what it wan...<br>**Metadata:** {'page_number': 27, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant', 'chunk_size': 512}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(\n",
    "    response, show_source=True, source_length=500, show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Relative Importance of Each Chunk\n",
    "\n",
    "An interesting feature of ensemble-based retrieval is that reranking allows us to assess the importance of each chunk size based on their order in the final retrieved set. \n",
    "\n",
    "For example, if certain chunk sizes consistently rank near the top, they are likely more relevant to the query.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "The goal is to evaluate the relative importance or relevance of different metadata values (such as chunk sizes) by analyzing their ranks in the list. \n",
    "\n",
    "A higher MRR indicates that a specific metadata value tends to appear earlier in the ranking, implying higher relevance or importance.\n",
    "\n",
    "\n",
    "1. **Input Parameters**:\n",
    "    - **metadata_values**: A list of unique values for a specific metadata key that you want to evaluate (e.g., different chunk sizes).\n",
    "\n",
    "    - **metadata_key**: The specific metadata key to check in each node (e.g., \"chunk_size\").\n",
    "\n",
    "    - **source_nodes**: A ranked list of nodes, each containing metadata.\n",
    "\n",
    "2. **Process**:\n",
    "\n",
    "    - For each metadata value, iterate through the ranked list of source nodes.\n",
    "\n",
    "    - Identify the position of the first occurrence of the metadata value in the list.\n",
    "\n",
    "    - Compute the reciprocal rank (1 divided by the position index + 1) for that value.\n",
    "\n",
    "    - Store these reciprocal ranks in a dictionary.\n",
    "\n",
    "3. **Output**:\n",
    "\n",
    "    - Convert the dictionary of MRR values into a Pandas DataFrame.\n",
    "    \n",
    "    - Return the DataFrame, which displays the MRR for each metadata value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average precision for each chunk size based on positioning in combined ranking\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def mrr_all(metadata_values, metadata_key, source_nodes):\n",
    "    # source nodes is a ranked list\n",
    "    # go through each value, find out positioning in source_nodes\n",
    "    value_to_mrr_dict = {}\n",
    "    for metadata_value in metadata_values:\n",
    "        mrr = 0\n",
    "        for idx, source_node in enumerate(source_nodes):\n",
    "            if source_node.node.metadata[metadata_key] == metadata_value:\n",
    "                mrr = 1 / (idx + 1)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # normalize AP, set in dict\n",
    "        value_to_mrr_dict[metadata_value] = mrr\n",
    "\n",
    "    df = pd.DataFrame(value_to_mrr_dict, index=[\"MRR\"])\n",
    "    df.style.set_caption(\"Mean Reciprocal Rank\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for each Chunk Size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     128   256   512   1024\n",
       "MRR   1.0   0.5   0.2     0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the Mean Reciprocal Rank for each chunk size (higher is better)\n",
    "# we can see that chunk size of 128 has the highest ranked results.\n",
    "print(\"Mean Reciprocal Rank for each Chunk Size\")\n",
    "mrr_all(chunk_sizes, \"chunk_size\", response.source_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
