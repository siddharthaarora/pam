{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Query Engine\n",
    "\n",
    "When building a retrieval-augmented generation (RAG) application, experimenting with various query pipelines—such as top-k retrieval, keyword search, and knowledge graphs—is often necessary.\n",
    "\n",
    "**Concept**: What if we could simultaneously use multiple strategies and have a language model (LLM):\n",
    "\n",
    "1. Rate the relevance of each query result.\n",
    "\n",
    "2. Synthesize the results into a coherent answer.\n",
    "\n",
    "The Ensemble Query Engine allows you to do just that. This guide explains how to experiment with different query pipelines and strategies, have the LLM evaluate the relevance of each result, and synthesize the final response.\n",
    "\n",
    "## Key Purposes\n",
    "\n",
    "1. **Multi-Strategy Retrieval**: Try multiple retrieval strategies at once, such as top-k retrieval, keyword search, and knowledge graphs. This helps compare the effectiveness of various approaches.\n",
    "\n",
    "2. **Relevance Evaluation**: Have the LLM rate how pertinent each retrieved result is to the original query, ensuring only the most relevant information is considered.\n",
    "\n",
    "3. **Result Synthesis**: Let the LLM combine the most relevant information from different retrieval methods, leveraging its language understanding to create a comprehensive final answer.\n",
    "\n",
    "## How to Use the Ensemble Query Engine\n",
    "\n",
    "1. **Set Up Retrieval Tools**: Configure different retrieval tools, such as a keyword search tool and a vector search tool.\n",
    "\n",
    "2. **Configure the Router Query Engine**: Set up a router query engine with a selector to choose the relevant retrievals and a summarizer to synthesize the final answer.\n",
    "\n",
    "3. **Run Queries**: Use the router query engine to process queries and return synthesized responses that leverage multiple retrieval strategies evaluated by the LLM.\n",
    "\n",
    "## Benefits\n",
    "\n",
    "The Ensemble Query Engine enables you to harness the strengths of different retrieval methods and the reasoning capabilities of LLMs in a unified querying interface. It simplifies experimentation with various approaches, helping you find the optimal configuration for your RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 llama-index-embeddings-openai==0.1.9 qdrant-client==1.9.1 llama-index-vector-stores-qdrant==0.2.8 llama-index-llms-openai==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv(\"\")\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "from utils import setup_llm, setup_embed_model, setup_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDRANT_URL = os.environ['QDRANT_URL'] or getpass(\"Enter your Qdrant URL:\")\n",
    "\n",
    "QDRANT_URL=\":memory:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_API_KEY = os.environ['QDRANT_API_KEY'] or  getpass(\"Enter your Qdrant API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from utils import setup_llm, setup_embed_model\n",
    "\n",
    "setup_llm(\n",
    "    provider=\"openai\",\n",
    "    api_key=OPENAI_API_KEY, \n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0.75, \n",
    "    system_prompt=\"\"\"Use ONLY the provided context and generate a complete, coherent answer to the user's query. \n",
    "    Your response must be grounded in the provided context and relevant to the essence of the user's query.\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "setup_embed_model(\n",
    "    provider=\"openai\", \n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=OPENAI_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from utils import get_documents_from_docstore, group_documents_by_author, sample_documents\n",
    "\n",
    "documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "documents_by_author = group_documents_by_author(documents)\n",
    "\n",
    "senpai_documents = sample_documents(documents_by_author, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=128, chunk_overlap=8)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(senpai_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [`SimpleKeywordTableIndex`](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/indices/keyword_table/simple_base.py) Class Overview\n",
    "\n",
    "The `SimpleKeywordTableIndex` class is a simplified version of a keyword-based indexing system. \n",
    "\n",
    "During index construction, the KeywordTableIndex takes a dataset of text documents, chunks them, and uses GPT to extract relevant keywords. These keywords are stored in a table referencing the respective text chunk. \n",
    "\n",
    "During a query, the KeywordTableIndex extracts relevant keywords and uses them to retrieve a set of candidate text chunk IDs. The initial answer is constructed using the first text chunk and then refined with subsequent chunks.\n",
    "\n",
    "- **Index Construction**: \n",
    "    - Splits text documents into chunks.\n",
    "    - Extracts keywords for each chunk.\n",
    "    - Stores keywords in a table referencing the text chunks.\n",
    "\n",
    "- **Query Modes**:\n",
    "    - **Default**: Uses GPT for keyword extraction and constructs answers by refining text chunks.\n",
    "    - **Simple**: Uses regex for keyword extraction (implemented by `SimpleKeywordTableIndex`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e47aa369aea4d51a28540b4bfd747d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting keywords from nodes:   0%|          | 0/259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72f8e293714b0a99c656d78372c2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import SimpleKeywordTableIndex, VectorStoreIndex\n",
    "\n",
    "keyword_index = SimpleKeywordTableIndex(\n",
    "    nodes,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")\n",
    "vector_index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "QA_PROMPT_TMPL = \"\"\"\n",
    "Context:\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Based on the context above, answer the question below. If the answer is not in the context, \n",
    "inform the user without making up an answer. Additionally, provide a relevance score for the answer.\n",
    "\n",
    "Question: {query_str}\n",
    "Answer (with relevance score):\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)\n",
    "\n",
    "keyword_query_engine = keyword_index.as_query_engine(\n",
    "    text_qa_template=QA_PROMPT\n",
    ")\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine(text_qa_template=QA_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vector_query_engine.query(\n",
    "    \"What is the importance of focusing on who you work with and what you work on, rather than just how hard you work?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importance of focusing on who you work with and what you work on, rather than just how hard you work, is emphasized by Naval Ravikant as being more crucial than the amount of effort you put in. The context highlights that aligning yourself with the right people and the right projects can have a greater impact on your success than merely working hard. This includes leveraging your specific knowledge, accountability, and authentic skill set to position yourself to be the best in the world at what you do.\n",
      "\n",
      "Relevance score: 9/10\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = keyword_query_engine.query(\n",
    "    \"What is the importance of focusing on who you work with and what you work on, rather than just how hard you work?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importance of focusing on who you work with and what you work on, rather than just how hard you work, is highlighted in the context from \"The Almanack of Naval Ravikant\" by Naval Ravikant. The excerpt suggests that while hard work is necessary, the impact of your work is significantly influenced by the people you collaborate with and the projects you choose to engage in. This implies that strategic decisions about partnerships and project selection can lead to more meaningful and efficient outcomes, as opposed to merely increasing the amount of effort you put in.\n",
      "\n",
      "Relevance Score: 10/10\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [QueryEngineTool](https://github.com/run-llama/llama_index/blob/7849b1a851d88ee28e1bfd05d19f18e40d5b8e10/llama-index-core/llama_index/core/tools/query_engine.py#L17)\n",
    "\n",
    "Tools are abstractions designed to be used by data agents or LLMs and provide a structured way for them to perform tasks\n",
    "\n",
    "A `QueryEngineTool` is a specific type of tool designed to interface with and wrap existing query engines. It enables agents to perform complex queries by leveraging the capabilities of the underlying query engine.\n",
    "\n",
    "#### Use Cases\n",
    "\n",
    "- **Integrating Query Engines**: Allows agents to interact with query engines and other agents.\n",
    "\n",
    "- **Complex Query Handling**: Helps execute sophisticated queries and data retrieval operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "keyword_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=keyword_query_engine,\n",
    "    description=\"Useful for answering finding documents based on keywords and incomplete thoughts from a user.\",\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=\"Useful for answering fully-formed questions from a user.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Router Query Engine\n",
    "\n",
    "The [`LLMMultiSelector`](https://github.com/run-llama/llama_index/blob/7849b1a851d88ee28e1bfd05d19f18e40d5b8e10/llama-index-core/llama_index/core/selectors/llm_selectors.py#L141) uses LLMs to make decisions. Uses a prompt to present choices to the LLM, which then selects the most relevant options based on the query. It can be used alone or integrated into query engines and retrievers. \n",
    "\n",
    "#### Key Functions:\n",
    "\n",
    "1. **Data Source Selection**: Chooses the best data source from multiple options.\n",
    "\n",
    "2. **Operational Decisions**: Decides whether to perform summarization or semantic search.\n",
    "\n",
    "3. **Multi-Routing**: Evaluates multiple choices simultaneously and combines the results.\n",
    "\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- Selecting the right data source.\n",
    "- Choosing between summarization and semantic search.\n",
    "- Combining results from multiple choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMMultiSelector\n",
    "\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "\n",
    "TREE_SUMMARIZE_PROMPT_TMPL = \"\"\"\n",
    "Context from multiple sources is below. Each source may have a relevance score.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "Based on the information from the sources above, answer the question below. \n",
    "\n",
    "If the answer is not in the context, inform the user without making up an answer.\n",
    "\n",
    "Question: {query_str}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "tree_summarize = TreeSummarize(\n",
    "    summary_template=PromptTemplate(TREE_SUMMARIZE_PROMPT_TMPL)\n",
    ")\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMMultiSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        keyword_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    summarizer=tree_summarize,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Useful for answering fully-formed questions from a user..\n",
      "\u001b[0mThe context provided does not specifically address how to develop specific knowledge that will help build wealth and achieve happiness. It mentions the importance of avoiding ruin and making better decisions, but does not provide detailed strategies or steps for developing specific knowledge.\n",
      "\n",
      "Relevance score: 4/10\n"
     ]
    }
   ],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"How can I develop specific knowledge that will help me build wealth and achieve happiness?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The context provided does not specifically address how to develop specific knowledge that will help build wealth and achieve happiness. It mentions the importance of avoiding ruin and making better decisions, but does not provide detailed strategies or steps for developing specific knowledge.\n",
       "\n",
       "Relevance score: 4/10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2727d142-9426-4d52-9bfd-44116a286d15<br>**Similarity:** 0.43822466974483665<br>**Text:** technology and large workforces and capital, our decisions are leveraged more and more. If you can be more right and more rational, youre going to get nonlinear returns in your life. I love the blog Farnam Street because it really focuses on helping you be more accurate, an overall better decision-maker. Decision-making is everything. The more you know, the less you diversify.<br>**Metadata:** {'page_number': 76, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 577b4652-2f57-49bd-8b66-a1db03f5e355<br>**Similarity:** 0.4298802828072778<br>**Text:** The combination of those over a long period of time with the magic of compound interest will make you wealthy. The one thing you have to avoid is the risk of ruin. Avoiding ruin means stay out of jail. So, dont do anything ille-<br>**Metadata:** {'page_number': 36, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(\n",
    "    response, show_source=True, source_length=500, show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='2727d142-9426-4d52-9bfd-44116a286d15', embedding=None, metadata={'page_number': 76, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='789263af-c3cb-4204-9a25-69d886e33b73', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_number': 76, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}, hash='3a49e6f7304356b26fde4a4bdd5ca2747beef954f087319476965d27832e485c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bb5fcb9c-11fe-4f6e-b74b-8d5c02c66c12', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2c7fb28a5b690ce69c33842bf7c7f83eb7164010e9a14f92d362072b45aff070')}, text='technology and large workforces and capital, our decisions are leveraged more and more. If you can be more right and more rational, youre going to get nonlinear returns in your life. I love the blog Farnam Street because it really focuses on helping you be more accurate, an overall better decision-maker. Decision-making is everything. The more you know, the less you diversify.', start_char_idx=0, end_char_idx=379, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.43822466974483665),\n",
       " NodeWithScore(node=TextNode(id_='577b4652-2f57-49bd-8b66-a1db03f5e355', embedding=None, metadata={'page_number': 36, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4bae7766-6f8e-495b-82ea-ed8e803fbe52', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_number': 36, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}, hash='1880bdfa1b259857590e842efed286cc664af622d3c8c81b1edc9feb1f94c555'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='458881e2-700c-4b41-bac4-ab71f9b749ca', node_type=<ObjectType.TEXT: '1'>, metadata={'page_number': 36, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}, hash='ec639daaf7f291acdaa903d56a9740913dd6133e0c8b1d6505365c3f68465113')}, text='The combination of those over a long period of time with the magic of compound interest will make you wealthy. The one thing you have to avoid is the risk of ruin. Avoiding ruin means stay out of jail. So, dont do anything ille-', start_char_idx=1390, end_char_idx=1618, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4298802828072778)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The query 'specific knowledge, build wealth, achieve happiness?' consists of keywords and incomplete thoughts rather than a fully-formed question..\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The provided context does not explicitly address how to build wealth or achieve happiness through specific knowledge. However, there are relevant insights from the excerpts:\n",
       "\n",
       "1. **Building Wealth through Innovation and Risk-taking:**\n",
       "   - From \"The Anthology of Balaji Srinivasan,\" it emphasizes the golden age for builders, leveraging open source, 3D printing, app stores, and crowdfunding to de-risk, prototype, and accept global payments (page 151). This highlights that innovation and taking risks can be pathways to wealth.\n",
       "\n",
       "2. **Self-Knowledge and Happiness:**\n",
       "   - From \"Striking Thoughts\" by Bruce Lee, it discusses self-knowledge as the road to freedom and emphasizes understanding oneself from moment to moment (page 174). This suggests that self-awareness and inner understanding are crucial for achieving personal happiness.\n",
       "\n",
       "Relevance Score: 7/10\n",
       "- While the context provides insights into building wealth through innovation and achieving happiness through self-knowledge, it does not provide a comprehensive answer connecting all three aspects (specific knowledge, building wealth, achieving happiness) directly.\n",
       "\n",
       "If you have more specific questions or need further details, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 87d615bd-6676-4c47-8bb6-a6556f7cfc0b<br>**Similarity:** None<br>**Text:** Thats not a theoretical example. In China, theyre building skyscrapers in two weeks flat. You can see it on YouTube. They put up a camera and build twenty-four hours a day from prefab material assembled on site. Theyre building 100x faster than you can build in the US. In the US, it took ten years to rebuild the World Trade Center.<br>**Metadata:** {'page_number': 9, 'file_name': '../data/anthology_of_balaji.pdf', 'title': 'The Anthology of Balaji Srinivasan', 'author': 'Balaji Srinivasan'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8720b84c-fe30-4115-bf38-426943cc8853<br>**Similarity:** None<br>**Text:** We are entering a golden age for builders. Consider open source, 3D printing, app stores, and crowdfunding. One person can de-risk, prototype, and accept payments from around the globe. To influence the direction of tech, pick up a keyboard or put capital at risk. You can build something. Those who wont build will just preach.<br>**Metadata:** {'page_number': 151, 'file_name': '../data/anthology_of_balaji.pdf', 'title': 'The Anthology of Balaji Srinivasan', 'author': 'Balaji Srinivasan'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5f6316f2-d486-47c3-a90d-6bc2c89a7619<br>**Similarity:** None<br>**Text:** Self-knowledge as the road to freedom. - Freedom lies in understanding yourself from moment to moment. Attend to the inner self - The pursuit of pleasures deranges the mind of man. The love for wealth perverts the conduct of man. Therefore the Sage attends to the Inner Self, and not to the outward appearance. Self-knowledge and intelligence. - Intelligence is the understanding of self Awareness vs. robotics.<br>**Metadata:** {'page_number': 174, 'file_name': '../data/striking-thoughts.pdf', 'title': 'Striking Thoughts', 'author': 'Bruce Lee'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 4/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 75113ff8-86f7-45d2-9916-153b3ec84717<br>**Similarity:** None<br>**Text:** Knowledge is of the mind. - By knowledge is meant knowing the emptiness and tranquillity of the mind. Insight means realising the one's original nature is not created. Knowledge is of the past. - Knowledge is of the past; learning is in the present, a constant movement, in relationship with the outward things, without the past.<br>**Metadata:** {'page_number': 43, 'file_name': '../data/striking-thoughts.pdf', 'title': 'Striking Thoughts', 'author': 'Bruce Lee'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 5/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 475faf7e-5649-44b4-81bf-a847104492fb<br>**Similarity:** None<br>**Text:** the branches. - What we are after is the ROOT and not the branches. The root is the real knowledge; the branches are surface knowledge. Real knowledge breeds \"body feel\" and personal expression; surface knowledge breeds mechanical conditioning and imposing limitation and squelches creativity. Express your total presence from the root. - Be at once absorbingly open and rootily relaying your captivating total presence with appropriate inward time. The root is the starting point.<br>**Metadata:** {'page_number': 16, 'file_name': '../data/striking-thoughts.pdf', 'title': 'Striking Thoughts', 'author': 'Bruce Lee'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 6/6`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 28b6ed5e-737b-487c-8e6d-11e428d23ad1<br>**Similarity:** None<br>**Text:** Was it that Europeans are somehow racially superior? Was it their religion? The answer (or at least the proximate cause) may be that the Europeans rode on the crest of a powerful new idea: allowing those who made a lot of money to keep it. Once youre allowed to do that, people who want to get rich can do it by generating wealth instead of stealing it. The resulting technological growth translates not only into wealth but into military power.<br>**Metadata:** {'page_number': 107, 'file_name': '../data/hackers_and_painters.pdf', 'title': 'Hackers and Painters', 'author': 'Paul Graham'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"specific knowledge, build wealth, achieve happiness?\"\n",
    ")\n",
    "\n",
    "display_response(\n",
    "    response, show_source=True, source_length=500, show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The user's query is a fully-formed question seeking advice on achieving a calm mind and clear schedule..\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided context, to achieve a calm mind, clear schedule, and clear mind, you need to:\n",
       "\n",
       "1. Emancipate your mind from old habits, prejudices, restrictive thought processes, and even ordinary thought itself (Striking Thoughts, Bruce Lee).\n",
       "2. Cultivate an alert mind, which involves being sincere to oneself and staying serious and sincere in your pursuits (Striking Thoughts, Bruce Lee).\n",
       "3. Avoid letting your preconceived notions cloud your reality, particularly when mixing different aspects of your life such as politics and business (The Almanack of Naval Ravikant, Naval Ravikant).\n",
       "\n",
       "Relevance Score: 9/10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3d9b728d-4c72-4a78-981d-be905d632eb4<br>**Similarity:** 0.3515060115569545<br>**Text:** - [To] bring the mind into sharp focus and to make it alert so that it can immediately intuit truth, which is everywhere, the mind must be emancipated from old habits, prejudices, restrictive thought process, and even ordinary thought itself. Cultivate an alert mind. - To be on the alert means to be deadly serious; to be deadly serious means to be sincere to oneself, and it is sincerity that finally leads to the Way.<br>**Metadata:** {'page_number': 43, 'file_name': '../data/striking-thoughts.pdf', 'title': 'Striking Thoughts', 'author': 'Bruce Lee'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 74876a11-0f78-412b-94af-57d7d2bdfed2<br>**Similarity:** 0.3452401383699676<br>**Text:** The monkey mind will always respond with this regurgitated emotional response to what it thinks the world should be. Those desires will cloud your reality. This happens a lot of times when people are mixing politics and business. The number one thing clouding us from being able to see reality is we have preconceived notions of the way it should be.<br>**Metadata:** {'page_number': 66, 'file_name': '../data/almanack_of_naval_ravikant.pdf', 'title': 'The Almanack of Naval Ravikant', 'author': 'Naval Ravikant'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"Calm mind, clear schedule, clear mind. What do I need to do to achieve these?\"\n",
    ")\n",
    "display_response(\n",
    "    response, show_source=True, source_length=500, show_source_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
